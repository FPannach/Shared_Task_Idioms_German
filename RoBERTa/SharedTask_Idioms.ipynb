{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"TPU","colab":{"name":"SharedTask_Idioms.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"},"widgets":{"application/vnd.jupyter.widget-state+json":{"a6268c6d590a4de58fe2eaf2fb4087b8":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_a1257a4a0c23400db881577f4118f3d2","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_0e1261e2dea2469c959701523316a684","IPY_MODEL_90affc748f7447c2a015d2519bb02400"]}},"a1257a4a0c23400db881577f4118f3d2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"0e1261e2dea2469c959701523316a684":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_fdcd23f6272941a0a8796f7653962c59","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":5069051,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":5069051,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_e999a537ba04462f833d48fc4cc4a546"}},"90affc748f7447c2a015d2519bb02400":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_9843e65033bc440a80aab44ada3c8ee3","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 5.07M/5.07M [00:40&lt;00:00, 124kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_24999c9b8f60410c96bf3202fbbb787a"}},"fdcd23f6272941a0a8796f7653962c59":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"e999a537ba04462f833d48fc4cc4a546":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"9843e65033bc440a80aab44ada3c8ee3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"24999c9b8f60410c96bf3202fbbb787a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b4b2d18a04344d929c613ea58eb6add2":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_2c255c4a6fcf40f8a42f20fb6a893df5","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_15f88c611ed64ecdb2f1493735920f6e","IPY_MODEL_f292843ea17a406ca11fa3bccfedcdb4"]}},"2c255c4a6fcf40f8a42f20fb6a893df5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"15f88c611ed64ecdb2f1493735920f6e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_afdf6679446a4b66a35c39e4ba880f40","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":9096718,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":9096718,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_a6be9f4df94d437d863edf7b090ca7b3"}},"f292843ea17a406ca11fa3bccfedcdb4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_ba65243f6e39490ab4b3f8c0a29d9825","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 9.10M/9.10M [00:03&lt;00:00, 2.83MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_1aeb3e80276d4fa789afd24d4b317e2b"}},"afdf6679446a4b66a35c39e4ba880f40":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"a6be9f4df94d437d863edf7b090ca7b3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ba65243f6e39490ab4b3f8c0a29d9825":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"1aeb3e80276d4fa789afd24d4b317e2b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"jDudlxCAzEtY"},"source":["# Initialization"]},{"cell_type":"code","metadata":{"id":"D1H5fX80zEtc","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1626357134250,"user_tz":-120,"elapsed":9444,"user":{"displayName":"Franzi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgfEkaBJt2RnAK0ATg_4-JgKpq1YRfPIoXeej8bSA=s64","userId":"15803026054485246168"}},"outputId":"25d6704b-b5da-426c-d4ef-7c362e2cef44"},"source":["!pip install transformers[sentencepiece]"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Collecting transformers[sentencepiece]\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fd/1a/41c644c963249fd7f3836d926afa1e3f1cc234a1c40d80c5f03ad8f6f1b2/transformers-4.8.2-py3-none-any.whl (2.5MB)\n","\u001b[K     |████████████████████████████████| 2.5MB 5.3MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (1.19.5)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (4.41.1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (20.9)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (4.6.0)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (3.13)\n","Collecting huggingface-hub==0.0.12\n","  Downloading https://files.pythonhosted.org/packages/2f/ee/97e253668fda9b17e968b3f97b2f8e53aa0127e8807d24a547687423fe0b/huggingface_hub-0.0.12-py3-none-any.whl\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (2.23.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (3.0.12)\n","Collecting sacremoses\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n","\u001b[K     |████████████████████████████████| 901kB 38.4MB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (2019.12.20)\n","Collecting tokenizers<0.11,>=0.10.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/e2/df3543e8ffdab68f5acc73f613de9c2b155ac47f162e725dcac87c521c11/tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3MB)\n","\u001b[K     |████████████████████████████████| 3.3MB 14.5MB/s \n","\u001b[?25hRequirement already satisfied: protobuf; extra == \"sentencepiece\" in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (3.17.3)\n","Collecting sentencepiece==0.1.91; extra == \"sentencepiece\"\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f2/e2/813dff3d72df2f49554204e7e5f73a3dc0f0eb1e3958a4cad3ef3fb278b7/sentencepiece-0.1.91-cp37-cp37m-manylinux1_x86_64.whl (1.1MB)\n","\u001b[K     |████████████████████████████████| 1.1MB 37.3MB/s \n","\u001b[?25hRequirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers[sentencepiece]) (2.4.7)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers[sentencepiece]) (3.4.1)\n","Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers[sentencepiece]) (3.7.4.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers[sentencepiece]) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers[sentencepiece]) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers[sentencepiece]) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers[sentencepiece]) (2021.5.30)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers[sentencepiece]) (7.1.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers[sentencepiece]) (1.15.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers[sentencepiece]) (1.0.1)\n","Installing collected packages: huggingface-hub, sacremoses, tokenizers, sentencepiece, transformers\n","Successfully installed huggingface-hub-0.0.12 sacremoses-0.0.45 sentencepiece-0.1.91 tokenizers-0.10.3 transformers-4.8.2\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"W_RgUK6jzEte","executionInfo":{"status":"ok","timestamp":1626357141901,"user_tz":-120,"elapsed":7671,"user":{"displayName":"Franzi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgfEkaBJt2RnAK0ATg_4-JgKpq1YRfPIoXeej8bSA=s64","userId":"15803026054485246168"}}},"source":["import numpy as np\n","import tensorflow as tf\n","import pandas as pd\n","\n","import os, tqdm\n","\n","from transformers import XLMRobertaTokenizer, AdamWeightDecay\n","from transformers import TFXLMRobertaForSequenceClassification\n","from transformers.modeling_tf_outputs import TFTokenClassifierOutput\n","\n","from sklearn.metrics import classification_report"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"vnSbvNfGzEtf","executionInfo":{"status":"ok","timestamp":1626357141903,"user_tz":-120,"elapsed":32,"user":{"displayName":"Franzi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgfEkaBJt2RnAK0ATg_4-JgKpq1YRfPIoXeej8bSA=s64","userId":"15803026054485246168"}}},"source":["SEQ_LENGTH       = 128 # @param {type: \"integer\"}\n","TRAIN_BATCH_SIZE = 64  # @param {type: \"integer\"}\n","VALID_BATCH_SIZE = 512 # @param {type: \"integer\"}\n","EPOCHS           = 4   # @param {type: \"integer\"}\n","\n","LEARNING_RATE   = 2e-5 # @param {type: \"number\"}\n","L2_WEIGHT_DECAY = 0.01 # @param {type: \"number\"}\n","LR_DECAY        = 0.95 # @param {type: \"number\"}\n","\n","USE_TPU  = True # @param {type: \"boolean\"}\n","USE_FP16 = True  # @param {type: \"boolean\"}\n","\n","USE_TPU = USE_TPU and ('COLAB_TPU_ADDR' in os.environ)"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"3fpHFk3vzEth","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1626357156063,"user_tz":-120,"elapsed":14187,"user":{"displayName":"Franzi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgfEkaBJt2RnAK0ATg_4-JgKpq1YRfPIoXeej8bSA=s64","userId":"15803026054485246168"}},"outputId":"258f0fdd-e2bf-4ca9-c207-69cc6556fd39"},"source":["tf.random.set_seed(42)\n","\n","if USE_FP16:\n","    if USE_TPU:\n","        tf.keras.mixed_precision.set_global_policy('mixed_bfloat16')\n","    else:\n","        tf.keras.mixed_precision.set_global_policy('mixed_float16')\n","\n","if USE_TPU:\n","    resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='grpc://' + os.environ['COLAB_TPU_ADDR'])\n","    tf.config.experimental_connect_to_cluster(resolver)\n","    tf.tpu.experimental.initialize_tpu_system(resolver)\n","    tpu_strategy = tf.distribute.TPUStrategy(resolver)"],"execution_count":4,"outputs":[{"output_type":"stream","text":["INFO:absl:Entering into master device scope: /job:worker/replica:0/task:0/device:CPU:0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Initializing the TPU system: grpc://10.81.78.186:8470\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Initializing the TPU system: grpc://10.81.78.186:8470\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Clearing out eager caches\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Clearing out eager caches\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Finished initializing TPU system.\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Finished initializing TPU system.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Found TPU system:\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Found TPU system:\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Num TPU Cores: 8\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Num TPU Cores: 8\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Num TPU Workers: 1\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Num TPU Workers: 1\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"cdna2sDYzEtj","colab":{"base_uri":"https://localhost:8080/","height":116,"referenced_widgets":["a6268c6d590a4de58fe2eaf2fb4087b8","a1257a4a0c23400db881577f4118f3d2","0e1261e2dea2469c959701523316a684","90affc748f7447c2a015d2519bb02400","fdcd23f6272941a0a8796f7653962c59","e999a537ba04462f833d48fc4cc4a546","9843e65033bc440a80aab44ada3c8ee3","24999c9b8f60410c96bf3202fbbb787a","b4b2d18a04344d929c613ea58eb6add2","2c255c4a6fcf40f8a42f20fb6a893df5","15f88c611ed64ecdb2f1493735920f6e","f292843ea17a406ca11fa3bccfedcdb4","afdf6679446a4b66a35c39e4ba880f40","a6be9f4df94d437d863edf7b090ca7b3","ba65243f6e39490ab4b3f8c0a29d9825","1aeb3e80276d4fa789afd24d4b317e2b"]},"executionInfo":{"status":"ok","timestamp":1626357164531,"user_tz":-120,"elapsed":4375,"user":{"displayName":"Franzi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgfEkaBJt2RnAK0ATg_4-JgKpq1YRfPIoXeej8bSA=s64","userId":"15803026054485246168"}},"outputId":"3e2d3232-09fd-40e1-dfc6-f832b576abdd"},"source":["tokenizer = XLMRobertaTokenizer.from_pretrained('xlm-roberta-base')"],"execution_count":5,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a6268c6d590a4de58fe2eaf2fb4087b8","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=5069051.0, style=ProgressStyle(descript…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b4b2d18a04344d929c613ea58eb6add2","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=9096718.0, style=ProgressStyle(descript…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"o2RiLvtyzEtk"},"source":["# Prepare data"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TWli7VtFziH-","executionInfo":{"status":"ok","timestamp":1626357189560,"user_tz":-120,"elapsed":25034,"user":{"displayName":"Franzi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgfEkaBJt2RnAK0ATg_4-JgKpq1YRfPIoXeej8bSA=s64","userId":"15803026054485246168"}},"outputId":"93447f72-8f00-4b5e-b85f-5e96a45190fb"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"p5ANtq_BzEtk","executionInfo":{"status":"ok","timestamp":1626357197705,"user_tz":-120,"elapsed":8,"user":{"displayName":"Franzi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgfEkaBJt2RnAK0ATg_4-JgKpq1YRfPIoXeej8bSA=s64","userId":"15803026054485246168"}}},"source":["data_files = {'Deutsch': {\n","        'train': '/content/drive/MyDrive/Colab Notebooks/train.csv',\n","\n","        'dev':  '/content/drive/MyDrive/Colab Notebooks/test_blind.csv',\n","\n","        #'true': '/content/drive/MyDrive/Colab Notebooks/dev.csv'\n","    } }\n","\n","label_map = {\n","    'literally': 0,\n","    'figuratively':     1,\n","    'both':     2,\n","    'undecidable': 3\n","}"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"9Wl5M8hPsjPD","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1626357205826,"user_tz":-120,"elapsed":5779,"user":{"displayName":"Franzi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgfEkaBJt2RnAK0ATg_4-JgKpq1YRfPIoXeej8bSA=s64","userId":"15803026054485246168"}},"outputId":"0de91053-e3b2-4fb6-dbc0-dd20d761ef0e"},"source":["def _load_data(filename, is_train=0):\n","    train = pd.read_csv(filename, sep=\";\", encoding=\"utf-8\")\n","\n","    if is_train :\n","      cut_off_X, cut_off_y = len(train[\"text\"])%TRAIN_BATCH_SIZE,len(train[\"label\"])%TRAIN_BATCH_SIZE \n","      boundary_X = len(train[\"text\"])-cut_off_X-1\n","      boundary_y = len(train[\"label\"])-cut_off_y-1\n","\n","      X = tokenizer.batch_encode_plus(tqdm.tqdm(train[\"text\"][0:boundary_X]),\n","                                    padding        = 'max_length',\n","                                    truncation     = True,\n","                                    max_length     = 128)\n","      y = train[\"label\"][0:boundary_y].map(label_map).to_numpy(dtype=np.int32)\n","\n","    else :    \n","      X = tokenizer.batch_encode_plus(tqdm.tqdm(train[\"text\"]),\n","                                      padding        = 'max_length',\n","                                      truncation     = True,\n","                                      max_length     = 128)\n","      y = train[\"label\"].map(label_map).to_numpy(dtype=np.int32)\n","   \n","    X['input_ids']      = np.asarray(X['input_ids'], dtype=np.int32)\n","    X['attention_mask'] = np.asarray(X['attention_mask'], dtype=np.float32)\n","    \n","        \n","    return X, y\n","\n","data_dict = {}\n","\n","for lang, files in data_files.items():\n","    X_train, y_train = _load_data(files['train'], 1)\n","    X_dev,   y_dev   = _load_data(files['dev'], 0)\n","   # X_dev = (X_dev[\"input_ids\"], X_dev[\"attention_mask\"])\n","\n","    data_dict['X_{}_train_ids'.format(lang)]  = X_train['input_ids']\n","    data_dict['X_{}_train_mask'.format(lang)] = X_train['attention_mask']\n","    data_dict['y_{}_train'.format(lang)]      = y_train\n","\n","    data_dict['X_{}_dev_ids'.format(lang)]  = X_dev['input_ids']\n","    data_dict['X_{}_dev_mask'.format(lang)] = X_dev['attention_mask']\n","    data_dict['y_{}_dev'.format(lang)]      = y_dev"],"execution_count":8,"outputs":[{"output_type":"stream","text":["100%|██████████| 6847/6847 [00:02<00:00, 2444.67it/s]\n","100%|██████████| 1511/1511 [00:00<00:00, 2669.15it/s]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"CwoMgj73eEgT","executionInfo":{"status":"ok","timestamp":1626357211951,"user_tz":-120,"elapsed":435,"user":{"displayName":"Franzi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgfEkaBJt2RnAK0ATg_4-JgKpq1YRfPIoXeej8bSA=s64","userId":"15803026054485246168"}}},"source":["X_train = (X_train[\"input_ids\"], X_train[\"attention_mask\"])"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"XWrakBTLdbYT","executionInfo":{"status":"ok","timestamp":1626357215261,"user_tz":-120,"elapsed":477,"user":{"displayName":"Franzi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgfEkaBJt2RnAK0ATg_4-JgKpq1YRfPIoXeej8bSA=s64","userId":"15803026054485246168"}}},"source":["sample_weights_train = np.full(y_train.shape,   1, dtype=np.float32)"],"execution_count":10,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"t-wTnfdjzEtp"},"source":["# Prepare the model"]},{"cell_type":"code","metadata":{"id":"CNe2cCXwzEtp","executionInfo":{"status":"ok","timestamp":1626357238293,"user_tz":-120,"elapsed":749,"user":{"displayName":"Franzi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgfEkaBJt2RnAK0ATg_4-JgKpq1YRfPIoXeej8bSA=s64","userId":"15803026054485246168"}}},"source":["class TFXLMRobertaForHopeSpeechDetection(TFXLMRobertaForSequenceClassification):\n","\n","    def call(\n","        self,\n","        input_ids=None,\n","        attention_mask=None,\n","        token_type_ids=None,\n","        position_ids=None,\n","        head_mask=None,\n","        inputs_embeds=None,\n","        output_attentions=None,\n","        output_hidden_states=None,\n","        return_dict=None,\n","        labels=None,\n","        training=False,\n","        **kwargs,\n","    ):\n","        _kwargs = {'labels': labels, 'training': training, **kwargs}\n","        if output_attentions is not None:\n","            _kwargs['output_attentions'] = output_attentions\n","        if output_hidden_states is not None:\n","            _kwargs['output_hidden_states'] = output_hidden_states\n","        if return_dict is not None:\n","            _kwargs['return_dict'] = return_dict\n","        \n","        outputs = super(TFXLMRobertaForHopeSpeechDetection, self).call(input_ids,\n","                                                                       attention_mask,\n","                                                                       token_type_ids,\n","                                                                       position_ids,\n","                                                                       head_mask,\n","                                                                       inputs_embeds,\n","                                                                       **_kwargs)\n","\n","        if 'mixed' in self.dtype_policy.name.lower():\n","            return_dict = return_dict if return_dict is not None else self.config.return_dict\n","            \n","            if return_dict:\n","                dtype = self.dtype_policy.variable_dtype\n","                \n","                outputs = TFTokenClassifierOutput(\n","                    loss          = None if outputs.loss is None else tf.cast(outputs.loss, dtype),\n","                    logits        = None if outputs.logits is None else tf.cast(outputs.logits, dtype),\n","                    hidden_states = None if outputs.hidden_states is None else tf.cast(outputs.hidden_states, dtype),\n","                    attentions    = None if outputs.attentions is None else tf.cast(outputs.attentions, dtype),\n","                )\n","            else:\n","                outputs = tuple(tf.cast(o, self.dtype_policy.variable_dtype) for o in outputs)\n","        \n","        return outputs\n","    \n","    \n","    def compile(self, optimizer='Adam', lr_decay=None, loss=None, metrics=None,\n","                      loss_weights=None, weighted_metrics=None, run_eagerly=None,\n","                      **kwargs):    \n","        # We use unaltered embeddings, because the training set only contains a\n","        # small subset of all possible tokens, leaving most embeddings untrained\n","        # anyway.\n","        self.roberta.embeddings.trainable = False\n","\n","        opt_weights = False\n","\n","        if lr_decay:\n","            optim_dict    = tf.keras.optimizers.serialize(optimizer)\n","            learning_rate = optim_dict['config']['learning_rate']\n","\n","            optimizer   = [optimizer]\n","            opt_weights = [self.classifier.trainable_weights]\n","\n","            n_layers = len(self.roberta.encoder.layer)\n","\n","            with self.distribute_strategy.scope():\n","                for i, layer in enumerate(self.roberta.encoder.layer, 1):\n","                    lr = learning_rate * (lr_decay ** (n_layers - i))\n","\n","                    if optim_dict['class_name'] == 'AdamWeightDecay':\n","                        optimizer.append(AdamWeightDecay(**{\n","                            **optim_dict['config'],\n","                            'exclude_from_weight_decay': (\"LayerNorm\", \"layer_norm\", \"bias\"),\n","                            'learning_rate': lr\n","                        }))\n","                    else:\n","                        optimizer.append(tf.keras.optimizers.get({\n","                            'class_name': optim_dict['class_name'],\n","                            'config': {**optim_dict['config'], 'learning_rate': lr}\n","                        }))\n","                    \n","                    opt_weights.append(layer.trainable_weights)\n","\n","        self._opt_weights = opt_weights\n","\n","        super(TFXLMRobertaForHopeSpeechDetection, self).compile(optimizer = optimizer,\n","                                                                loss = loss,\n","                                                                metrics = metrics,\n","                                                                loss_weights = loss_weights,\n","                                                                weighted_metrics = weighted_metrics,\n","                                                                run_eagerly = run_eagerly,\n","                                                                **kwargs)\n","\n","\n","    def train_step(self, data):\n","        if not self._opt_weights:\n","            return super(TFXLMRobertaForHopeSpeechDetection, self).train_step(data)\n","\n","        x, y, sample_weight = tf.keras.utils.unpack_x_y_sample_weight(data)\n","\n","        all_weights = [w for ws in self._opt_weights for w in ws]\n","\n","        with tf.GradientTape(persistent=True, watch_accessed_variables=False) as tape:\n","            tape.watch(all_weights)\n","\n","            y_pred = self(x, training=True)\n","            loss   = self.compiled_loss(y, y_pred, sample_weight=sample_weight,\n","                                      regularization_losses=self.losses)\n","\n","        for optim, current_weights in zip(self.optimizer, self._opt_weights):\n","            optim.minimize(loss, current_weights, tape=tape)\n","\n","        self.compiled_metrics.update_state(y, y_pred, sample_weight=sample_weight)\n","\n","        return {m.name: m.result() for m in self.metrics}"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-QJcTjgBzEtq","scrolled":true,"executionInfo":{"status":"ok","timestamp":1626357649938,"user_tz":-120,"elapsed":148935,"user":{"displayName":"Franzi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgfEkaBJt2RnAK0ATg_4-JgKpq1YRfPIoXeej8bSA=s64","userId":"15803026054485246168"}},"outputId":"ecadc5b0-7eed-487d-df69-36afc1ea4052"},"source":["def create_model():    \n","    if L2_WEIGHT_DECAY:\n","        optimizer = AdamWeightDecay(learning_rate     = LEARNING_RATE,\n","                                    weight_decay_rate = L2_WEIGHT_DECAY,\n","                                    exclude_from_weight_decay = ('LayerNorm', 'layer_norm', 'bias'))\n","    else:\n","        optimizer = tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE)\n","    loss      = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n","    metrics   = tf.keras.metrics.SparseCategoricalAccuracy(name='acc')\n","    roberta   = TFXLMRobertaForHopeSpeechDetection.from_pretrained('xlm-roberta-base',\n","                                                                   num_labels  = 4,\n","                                                                   from_pt     = True)\n","    roberta.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n","    \n","    return roberta\n","\n","\n","if USE_TPU:\n","    with tpu_strategy.scope():\n","        roberta = create_model()\n","else:\n","    roberta = create_model()"],"execution_count":18,"outputs":[{"output_type":"stream","text":["All PyTorch model weights were used when initializing TFXLMRobertaForHopeSpeechDetection.\n","\n","Some weights or buffers of the TF 2.0 model TFXLMRobertaForHopeSpeechDetection were not initialized from the PyTorch model and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"kp3zefgdLhfT","executionInfo":{"status":"ok","timestamp":1626357651545,"user_tz":-120,"elapsed":8,"user":{"displayName":"Franzi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgfEkaBJt2RnAK0ATg_4-JgKpq1YRfPIoXeej8bSA=s64","userId":"15803026054485246168"}}},"source":["def make_class_weights():\n","    values = np.bincount(y_train)\n","    total = len(y_train)\n","\n","    weight_for_0 = (1 / values[0]) * (total / 2.0)\n","    weight_for_1 = (1 / values[1]) * (total / 2.0)\n","    weight_for_2 = 0.01\n","    weight_for_3 = 0.01\n","\n","    class_weight = {0: weight_for_0, 1: weight_for_1, 2: weight_for_2, 3: weight_for_3}\n","\n","    return(class_weight)"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"id":"5eULERFHPjRB","executionInfo":{"status":"ok","timestamp":1626357651547,"user_tz":-120,"elapsed":9,"user":{"displayName":"Franzi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgfEkaBJt2RnAK0ATg_4-JgKpq1YRfPIoXeej8bSA=s64","userId":"15803026054485246168"}}},"source":["class_weights = make_class_weights()"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"652Bxt7CfpTG","executionInfo":{"status":"ok","timestamp":1625048703031,"user_tz":-120,"elapsed":19,"user":{"displayName":"Franzi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgfEkaBJt2RnAK0ATg_4-JgKpq1YRfPIoXeej8bSA=s64","userId":"15803026054485246168"}},"outputId":"48615628-d746-450f-ff7d-0864047fe8bf"},"source":["class_weights"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{0: 2.9285714285714284, 1: 0.6056076419600211, 2: 0.01, 3: 0.01}"]},"metadata":{"tags":[]},"execution_count":15}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ue9AqusJVguL","executionInfo":{"status":"ok","timestamp":1625048703031,"user_tz":-120,"elapsed":13,"user":{"displayName":"Franzi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgfEkaBJt2RnAK0ATg_4-JgKpq1YRfPIoXeej8bSA=s64","userId":"15803026054485246168"}},"outputId":"865ab71a-ff85-487a-d8e5-8b13a963a402"},"source":["np.bincount(y_train)\n","y_train"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0, 0, 1, ..., 1, 1, 1], dtype=int32)"]},"metadata":{"tags":[]},"execution_count":16}]},{"cell_type":"code","metadata":{"id":"R5_6XD1Fcjv-","executionInfo":{"status":"ok","timestamp":1626357651549,"user_tz":-120,"elapsed":9,"user":{"displayName":"Franzi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgfEkaBJt2RnAK0ATg_4-JgKpq1YRfPIoXeej8bSA=s64","userId":"15803026054485246168"}}},"source":["import time\n","start = time.time()"],"execution_count":21,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3sVCip80zEtr"},"source":["# Train the model"]},{"cell_type":"code","metadata":{"id":"I7SfARcEzEtr","scrolled":false,"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1626357812550,"user_tz":-120,"elapsed":159887,"user":{"displayName":"Franzi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgfEkaBJt2RnAK0ATg_4-JgKpq1YRfPIoXeej8bSA=s64","userId":"15803026054485246168"}},"outputId":"06ecbe18-6a39-4631-e8bd-d6381a4b51f3"},"source":["roberta.fit(x = X_train,\n","            y = y_train,\n","            sample_weight   = sample_weights_train,\n","            batch_size      = TRAIN_BATCH_SIZE,\n","            epochs          = EPOCHS,\n","            class_weight=class_weights\n","            )"],"execution_count":22,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/array_ops.py:5049: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\n","Instructions for updating:\n","The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/array_ops.py:5049: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\n","Instructions for updating:\n","The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/4\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:absl:TPU has inputs with dynamic shapes: [<tf.Tensor 'Const:0' shape=() dtype=int32>, <tf.Tensor 'cond_8/Identity:0' shape=(None, 128) dtype=int32>, <tf.Tensor 'cond_8/Identity_1:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'cond_8/Identity_2:0' shape=(None,) dtype=int32>, <tf.Tensor 'cond_8/Identity_3:0' shape=(None, 1) dtype=float32>]\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n","WARNING:tensorflow:AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7f04b4d40de0>> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7f04b4d40de0>> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING: AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7f04b4d40de0>> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function wrap at 0x7f04d05eedd0> and will run it as-is.\n","Cause: while/else statement not yet supported\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n","WARNING:tensorflow:AutoGraph could not transform <function wrap at 0x7f04d05eedd0> and will run it as-is.\n","Cause: while/else statement not yet supported\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n","WARNING: AutoGraph could not transform <function wrap at 0x7f04d05eedd0> and will run it as-is.\n","Cause: while/else statement not yet supported\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n","INFO:absl:TPU has inputs with dynamic shapes: [<tf.Tensor 'Const:0' shape=() dtype=int32>, <tf.Tensor 'cond_8/Identity:0' shape=(None, 128) dtype=int32>, <tf.Tensor 'cond_8/Identity_1:0' shape=(None, 128) dtype=float32>, <tf.Tensor 'cond_8/Identity_2:0' shape=(None,) dtype=int32>, <tf.Tensor 'cond_8/Identity_3:0' shape=(None, 1) dtype=float32>]\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["107/107 [==============================] - 125s 88ms/step - loss: 0.6557 - acc: 0.6657\n","Epoch 2/4\n","107/107 [==============================] - 9s 89ms/step - loss: 0.3967 - acc: 0.8369\n","Epoch 3/4\n","107/107 [==============================] - 9s 89ms/step - loss: 0.2572 - acc: 0.8940\n","Epoch 4/4\n","107/107 [==============================] - 10s 89ms/step - loss: 0.1705 - acc: 0.9262\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7f03d44c3e50>"]},"metadata":{"tags":[]},"execution_count":22}]},{"cell_type":"code","metadata":{"id":"jTrwesfNcpmD","executionInfo":{"status":"ok","timestamp":1626357813945,"user_tz":-120,"elapsed":11,"user":{"displayName":"Franzi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgfEkaBJt2RnAK0ATg_4-JgKpq1YRfPIoXeej8bSA=s64","userId":"15803026054485246168"}}},"source":["end = time.time()\n"],"execution_count":23,"outputs":[]},{"cell_type":"code","metadata":{"id":"5LCy37cfexNx","executionInfo":{"status":"ok","timestamp":1626357832791,"user_tz":-120,"elapsed":16,"user":{"displayName":"Franzi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgfEkaBJt2RnAK0ATg_4-JgKpq1YRfPIoXeej8bSA=s64","userId":"15803026054485246168"}},"outputId":"e4b12ff9-8134-4642-b3a8-d81f9b34be21","colab":{"base_uri":"https://localhost:8080/"}},"source":["print(end-start)"],"execution_count":24,"outputs":[{"output_type":"stream","text":["162.33856463432312\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"QvWTB-JIzEts"},"source":["roberta.save_pretrained('/content/drive/MyDrive/Colab Notebooks/saved_model_final1/')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FeUb2KS5zEtt"},"source":["# Evaluation"]},{"cell_type":"code","metadata":{"id":"eJkhWYpzsf4j"},"source":["y_pred_deutsch = roberta(X_dev).logits.numpy().argmax(-1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cWkJxbBi6j81"},"source":["true = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/dev.csv', sep=\";\", encoding=\"utf-8\", index_col=0)\n","y_true = true[\"label\"].map(label_map).to_numpy(dtype=np.int32)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FZsM08B_6XXa","executionInfo":{"status":"ok","timestamp":1625048988636,"user_tz":-120,"elapsed":48,"user":{"displayName":"Franzi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgfEkaBJt2RnAK0ATg_4-JgKpq1YRfPIoXeej8bSA=s64","userId":"15803026054485246168"}},"outputId":"f56b9b53-9d92-4f6a-ef09-067618502906"},"source":["print(true.iloc[0])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["src_id                                       T951103.116.45\n","idiom                                       an Boden liegen\n","label                                                  both\n","text      Minute glich Obradovic erstmals aus ( 91:91 ) ...\n","Name: 0, dtype: object\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"j-gJ97EWWPcT"},"source":[""]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4ReaxYo_6YRO","executionInfo":{"status":"ok","timestamp":1625048988637,"user_tz":-120,"elapsed":39,"user":{"displayName":"Franzi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgfEkaBJt2RnAK0ATg_4-JgKpq1YRfPIoXeej8bSA=s64","userId":"15803026054485246168"}},"outputId":"4f934817-0a5e-4d0d-d570-b370945f50ac"},"source":["print(classification_report(\n","    y_true = y_true,\n","    y_pred = y_pred_deutsch,\n","    target_names = ('literally', 'figuratively', 'both', 'undecidable'),\n","    digits = 4\n","  )\n",")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","   literally     0.6523    0.9167    0.7622       264\n","figuratively     0.9776    0.8995    0.9369      1214\n","        both     0.0000    0.0000    0.0000         2\n"," undecidable     0.0000    0.0000    0.0000         8\n","\n","    accuracy                         0.8965      1488\n","   macro avg     0.4075    0.4540    0.4248      1488\n","weighted avg     0.9133    0.8965    0.8996      1488\n","\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"FIB3P6el-75J"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lOqLFl8zDYMw"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_fAlPLRvzEtu"},"source":["# Create submission files"]},{"cell_type":"code","metadata":{"id":"xhcRphuvzEtv"},"source":["label_map_reverse = {\n","    0: 'literally',\n","    1: 'figuratively',\n","    2: 'both',\n","    3: 'undecidable'\n","}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aujVVK4bjV34"},"source":["def map_back(y_pred):\n","  y_string_rep = []\n","  for y in y_pred : \n","    y_string_rep.append(label_map_reverse[y])\n","  return y_string_rep"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wX7XHe0Jju_T"},"source":["pred_string = map_back(y_pred_deutsch) "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YWq9CYOuj1nD"},"source":["dev = pd.read_csv(data_files[\"Deutsch\"][\"dev\"], sep=\";\", encoding=\"utf-8\", index_col=0)\n","dev[\"label\"] = pred_string"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SfJDsnPNmax4"},"source":["file = open(\"/content/drive/MyDrive/Colab Notebooks/predictions_train_only.tsv\", \"w\")\n","for index, row in dev.iterrows():\n","    file.write(row['src_id']+\"\\t\"+row['idiom']+\"\\t\"+row['label']+\"\\t\"+row['text']+\"\\n\")\n","file.close()"],"execution_count":null,"outputs":[]}]}